---
title : テキストマイニング入門
author : Shinji KAWASOE
output :
  html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: readable
---
Data : `r Sys.Date()`

# 概要
目的は、「テキストマイニング入門」でどのような事ができるのかをイメージする。

参考図書：Rによるテキストマイング入門 第2版 石田基広

```{r}
## ライブラリ
library(RMeCab)
library(tidyverse)
library(igraph)
library(ggdendro)
library(tm)
library(lda)
library(topicmodels)
```

# RMeCab
短いテキストの解析

```{r}
RMeCabC("今日は本を読んだ。") %>% unlist()

hon <- RMeCabC("今日は本を読んだ。") %>% unlist()
hon [names(hon) %in% c("名詞", "動詞")]
```
活用語を表層語から原形にする。
```{r}
RMeCabC("今日は本を読んだ。", 1) %>% unlist()
```

# ウェブスクレイピング

SNSである「読書メーター」からの書評テキスト取り出し。  
取得部分は別途(todo)。取得後からのデータ加工。

```{r}
file.exists("data/revi.csv")

revi <- read.csv("data/revi.csv", stringsAsFactor = FALSE)

revi %>% filter(POS1 == "名詞") %>% head(10)

revi %>% filter(POS1 == "名詞", POS2 %in% c("一般", "固有名詞")) %>% head(10)

revi %>% filter(POS1 == "動詞") %>% head(10)

revi %>% filter(POS1 == "形容詞") %>% head(10)

revi2 <- revi %>% filter(POS2 %in% c("一般","固有名詞", "自立"))

revi2 %>% NROW()
```

# バイグラムとネットワークグラフ


```{r}
bigram <- read.csv("data/bigram.csv", stringsAsFactor = FALSE)

bigram %>% arrange(reviews.txt) %>% tail(10)

bigram2 <- bigram %>%
    select (N1, N2, reviews.txt) %>%
    filter(reviews.txt > 1)

bigram2 %>% head(10)



bigramN <- graph_from_data_frame(bigram2)

## tkplot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)

plot(bigramN, vertex.color = "SkyBlue", vertex.size = 22)
```

# テキストの分類

## クラスター分析

```{r, results = 'hide'}
prime <- docMatrix2("data/prime/sjis", pos = c("名詞","形容詞", "動詞"),
                    weight = "tf*idf*norm")
```
```{r}
ncol(prime); nrow(prime)

str(prime)

colnames(prime) <- colnames(prime) %>%
    str_replace("_general-policy-speech.txt", "")
colnames(prime) <- colnames(prime) %>%
    str_replace("(\\d{4})\\d{4}_(\\d{3})", "\\1_\\2")
colnames(prime) <- colnames(prime) %>%
    str_replace("(\\d{4})\\d{4}_(\\d{2})", "\\1_\\2")

str(prime)

hc <- prime %>% t() %>% dist() %>% hclust("ward.D2")

ggdendrogram(hc, rotate = TRUE)
```

## トピックモデル

```{r, results = 'hide'}
prime <- docDF("data/prime/sjis", type = 1,
               pos = c("名詞", "形容詞"), minFreq = 3)
```
```{r}
dim(prime)

prime2 <- prime %>% filter(POS2 %in% c("一般", "自立"))

dim(prime2)

prime2$TERM %>% duplicated() %>% which()

prime3 <- prime2 %>% select(-c(TERM:POS2))

## 列名に形態素を設定
rownames(prime3) <- prime2$TERM

colnames(prime3) <- 
    colnames(prime3) %>%
    str_replace("_general-policy-speech.txt","")

colnames(prime3) <- 
    colnames(prime3) %>%
    str_replace("(\\d{4})\\d{4}_(\\d{3})", "\\1_\\2")

prime3a <- prime3 %>% t() %>% as.DocumentTermMatrix(weighting = weightTf)
```
```{r}
K <- 5
system.time(
res1 <- prime3a %>% LDA(K))
```
```{r}
terms(res1)

posterior(res1)[[1]][1:5, 1:10]

## posterior(res1)[[2]]

prime4 <- dtm2ldaformat(prime3a)


set.seed(123)
K <- 5
result <- lda.collapsed.gibbs.sampler(prime4$documents, K = K,
                                      prime4$vocab, 25, 0.1, 0.1, compute.log.likelihood = TRUE)


top.topic.words(result$topics, 10, by.score = TRUE)
```
小泉、鳩山、野田、安倍(第二期)それぞれの就任時演説について、トピックの比重を確認する。
```{r}
prime5 <- rownames(prime3a) %>%
    str_subset("koizumi|hatoyama|noda|abe")

prime5

prime6 <- rownames(prime3a) %>%
    str_detect("koizumi|hatoyama|noda|abe") %>%
    which()

prime6

cbind(prime6, prime5)

## 文書全体のトピック割合
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)

## 対象とする所信表明演説を抽出
ministers <- topic.proportions [c(64,74,77,80), ]

ministers

ministers %>% rowSums()

## 行列をデータフレームに変換し列名を設定
ministersDF <- as.data.frame(ministers) %>%
    set_names(paste0("topic", 1:5)) %>%
    mutate(num = paste0("No", c(64, 74, 77, 80)))

ministersDF

ministersDF <- ministersDF %>%
    gather(key = topic, value = props, -num)
```

* No.64 小泉氏
* No.74 鳩山氏
* No.77 野田氏
* No.80 安倍氏

```{r}
ministersDF %>%
    ggplot(aes(x = topic, y = props, fill = num)) +
    geom_bar(stat = "identity") +
    facet_wrap(~ num)

top.topic.words(result$topics, 5, by.score = TRUE)
```

# Twitterタイムラインの分析

todo
